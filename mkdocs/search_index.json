{
    "docs": [
        {
            "location": "/",
            "text": "Introduction\n\n\nThis page provides an implementation of our mirror-based camera calibration algorithm presented as\n\n\nK. Takahashi, S. Nobuhara and T. Matsuyama: A New Mirror-based Extrinsic Camera Calibration Using an Orthogonality Constraint, CVPR2012\n\n\n\n\nand\n\n\nK. Takahashi, S. Nobuhara and T. Matsuyama: Mirror-based Camera Pose Estimation Using an Orthogonality Constraint, IPSJ Transactions on Computer Vision and Applications, Vol.8, pp.11--19, 2016\n\n\n\n\n\n\npaper: \nCVPR\n,  \nIPSJ Transactions on Computer Vision and Applications\n\n\nmovie: \nmp4\n\n\nbibtex:\n@inproceedings{takahashi12new,\n  title = {A New Mirror-based Extrinsic Camera Calibration Using an Orthogonality Constraint},\n  author = {Kosuke Takahashi and Shohei Nobuhara and Takashi Matsuyama},\n  booktitle = {Proc.\\ of CVPR},\n  year = {2012},\n}\n@article{takahashi2016mirror,\n  title={Mirror-based Camera Pose Estimation Using an Orthogonality Constraint},\n  author={Kosuke Takahashi and Shohei Nobuhara and Takashi Matsuyama},\n  journal={IPSJ Transactions on Computer Vision and Applications},\n  volume={8},\n  number={ },\n  pages={11-19},\n  year={2016}\n}\n\n\n\n\n\n\n\nThe motivation of this project is to calibrate a camera w.r.t. a reference object which is not observable from the camera. This happens, for example, in display-camera systems such\nas digital signage, webcam attached to laptop PC, etc. Once obtained the mapping between the display pixel coordinate system and the camera coordinate system, it becomes possible to\n compute the gazing point (pixel) of a person in front of the display by estimating the gazing direction in the camera coordinate system. This scenario allows the person to move fre\nely, while conventional methods typically restrict the head position to be fixed.\n\n\nThe key point to solve the problem is the use of mirrored images.\nSuppose we have a single static camera $$C$$ and a static reference object $$X$$ as shown below.\nThe camera $$C$$ cannot observe the reference object $$X$$ directly.\nInstead, we use a mirror $$\\pi$$ and let the camera $$C$$ observe the reference object $$X$$ through it.\nThe goal of our mirror-based calibration is to estimate the relative posture $$R$$ and position $$T$$ of the camera $$C$$ against the reference object $$X$$ by observing three point\ns of $$X$$ via three mirrors $$\\pi_j (j=1,2,3)$$ under different unknown positions and orientations.\n\n\n\n\nSource code\n\n\nLicense\n\n\nThis source code is provided under the \nBSD 3-Clause license\n.\n\n\nCopyright (c) 2012, Kosuke Takahashi, Shohei Nobuhara and Takashi Matsuyama\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n   * Redistributions of source code must retain the above copyright notice,\n     this list of conditions and the following disclaimer.\n   * Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n   * Neither the name of the Graduate School of Informatics, Kyoto\n     University, Japan nor the names of its contributors may be used to\n     endorse or promote products derived from this software without specific\n     prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n\n\n\n\nDownload links\n\n\nIf you use this software, please consider citing the aforementioned paper in any resulting publication.\n\n\nVer.1 (CVPR, 3-points / 3-mirrors version)\n\n\n\n\nMatlab version with test data: \ntnm-matlab-v1.zip\n (tested with Matlab 2011b and 2012a. Also compatible with GNU Octave v3.6 + Octave-Forge)\n\n\nOpenCV version with test data: \ntnm-opencv-v1.zip\n (tested with Debian wheezy + libcv-dev package)\n\n\n\n\nSee the \ninstruction\n for details.\n\n\nVer.2 (CVA, n-points / m-mirrors version)\n\n\nPlease use the latest code at \nGitHub\n. See the \ninstruction\n for details.\n\n\nContact\n\n\n\n\nShohei NOBUHARA",
            "title": "Index"
        },
        {
            "location": "/#introduction",
            "text": "This page provides an implementation of our mirror-based camera calibration algorithm presented as  K. Takahashi, S. Nobuhara and T. Matsuyama: A New Mirror-based Extrinsic Camera Calibration Using an Orthogonality Constraint, CVPR2012  and  K. Takahashi, S. Nobuhara and T. Matsuyama: Mirror-based Camera Pose Estimation Using an Orthogonality Constraint, IPSJ Transactions on Computer Vision and Applications, Vol.8, pp.11--19, 2016   paper:  CVPR ,   IPSJ Transactions on Computer Vision and Applications  movie:  mp4  bibtex: @inproceedings{takahashi12new,\n  title = {A New Mirror-based Extrinsic Camera Calibration Using an Orthogonality Constraint},\n  author = {Kosuke Takahashi and Shohei Nobuhara and Takashi Matsuyama},\n  booktitle = {Proc.\\ of CVPR},\n  year = {2012},\n}\n@article{takahashi2016mirror,\n  title={Mirror-based Camera Pose Estimation Using an Orthogonality Constraint},\n  author={Kosuke Takahashi and Shohei Nobuhara and Takashi Matsuyama},\n  journal={IPSJ Transactions on Computer Vision and Applications},\n  volume={8},\n  number={ },\n  pages={11-19},\n  year={2016}\n}    The motivation of this project is to calibrate a camera w.r.t. a reference object which is not observable from the camera. This happens, for example, in display-camera systems such\nas digital signage, webcam attached to laptop PC, etc. Once obtained the mapping between the display pixel coordinate system and the camera coordinate system, it becomes possible to\n compute the gazing point (pixel) of a person in front of the display by estimating the gazing direction in the camera coordinate system. This scenario allows the person to move fre\nely, while conventional methods typically restrict the head position to be fixed.  The key point to solve the problem is the use of mirrored images.\nSuppose we have a single static camera $$C$$ and a static reference object $$X$$ as shown below.\nThe camera $$C$$ cannot observe the reference object $$X$$ directly.\nInstead, we use a mirror $$\\pi$$ and let the camera $$C$$ observe the reference object $$X$$ through it.\nThe goal of our mirror-based calibration is to estimate the relative posture $$R$$ and position $$T$$ of the camera $$C$$ against the reference object $$X$$ by observing three point\ns of $$X$$ via three mirrors $$\\pi_j (j=1,2,3)$$ under different unknown positions and orientations.",
            "title": "Introduction"
        },
        {
            "location": "/#source-code",
            "text": "",
            "title": "Source code"
        },
        {
            "location": "/#license",
            "text": "This source code is provided under the  BSD 3-Clause license .  Copyright (c) 2012, Kosuke Takahashi, Shohei Nobuhara and Takashi Matsuyama\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n   * Redistributions of source code must retain the above copyright notice,\n     this list of conditions and the following disclaimer.\n   * Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n   * Neither the name of the Graduate School of Informatics, Kyoto\n     University, Japan nor the names of its contributors may be used to\n     endorse or promote products derived from this software without specific\n     prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.",
            "title": "License"
        },
        {
            "location": "/#download-links",
            "text": "If you use this software, please consider citing the aforementioned paper in any resulting publication.",
            "title": "Download links"
        },
        {
            "location": "/#ver1-cvpr-3-points-3-mirrors-version",
            "text": "Matlab version with test data:  tnm-matlab-v1.zip  (tested with Matlab 2011b and 2012a. Also compatible with GNU Octave v3.6 + Octave-Forge)  OpenCV version with test data:  tnm-opencv-v1.zip  (tested with Debian wheezy + libcv-dev package)   See the  instruction  for details.",
            "title": "Ver.1 (CVPR, 3-points / 3-mirrors version)"
        },
        {
            "location": "/#ver2-cva-n-points-m-mirrors-version",
            "text": "Please use the latest code at  GitHub . See the  instruction  for details.",
            "title": "Ver.2 (CVA, n-points / m-mirrors version)"
        },
        {
            "location": "/#contact",
            "text": "Shohei NOBUHARA",
            "title": "Contact"
        },
        {
            "location": "/v1/",
            "text": "Introduction\n\n\nThis page explains how to use the 3-points version. For the general n-pts version, see \nmatlab/demo.m\n in \nGitHub\n.\n\n\nHow to use the Matlab version with sample data\n\n\nUsage\n\n\nAfter unzipping the downloaded file, you will have the following files in a single directory named \ntnm\n.\n\n\n\n\ndata/input{1,2,3}.png\n : Three input images. They are the original pictures WITH lens distortions.\n\n\ndata/input{1,2,3}.txt\n : Three input data points extracted from \ninput{1,2,3}.png\n. The points are taken from undistorted images.\n\n\ncamera.txt\n : The intrinsic parameter of the camera.\n\n\nmodel.txt\n : The reference object.\n\n\ndemo.m\n : A demo program to run our method.\n\n\ntnm.m\n : An implementation of our calibration method.\n\n\nsub_p3p.m\n : A sub-function called from \ntnm.m\n to solve P3P problem.\n\n\nsub_tnm_orth.m\n : A sub-function called from \ntnm.m\n.\n\n\nsub_tnm_rt.m\n : A sub-function called from \ntnm.m\n.\n\n\nsub_reproj.m\n : To calc reprojection error.\n\n\n\n\nStart Matlab, and change the working directory to the \ntnm\n directory. Run \ndemo.m\n and you should see the following outputs and a pop-up window that visualizes the results.\n\n\n> demo.m\nAverage reprojection error by TNM : 0.353531 pixel.\n\n==== Parameters by TNM ====\nR =\n    0.9552   -0.0316   -0.2942\n    0.0262    0.9994   -0.0221\n    0.2947    0.0134    0.9555\nT =\n   71.6716\n   84.3404\n  120.2696\nn1 =\n    0.2679\n    0.0307\n   -0.9629\nn2 =\n    0.4356\n    0.0844\n   -0.8962\nn3 =\n   -0.0443\n   -0.0112\n   -0.9990\nd1 =\n  386.2302\nd2 =\n  355.0478\nd3 =\n  404.7066\n\n\n\n\nBrief descriptions of the code\n\n\ntnm.m\n : top-level driver\n\n\nThe figure below illustrates the measurement model of our method.\n\n\n\n\nIn this figure, we use the following notations. Notice that $${}^Yx$$ denotes $$x$$ in $$Y$$ coordinate system.\n\n\n\n\n$$C$$ : camera.\n\n\n$$\\pi_j (j=1,2,3)$$ : three mirrors.\n\n\n$${}^Cn_j (j=1,2,3)$$ : the normal vector of $$\\pi_j$$.\n\n\n$$d_j (j=1,2,3)$$ : the distance from $$C$$ to $$\\pi_j$$.\n\n\n$${}^Xp^i (i=1,2,3)$$ : three reference points in the reference object coordinate system.\n\n\n$${}^Cp^i (i=1,2,3)$$ : $${}^Xp^i$$ in the camera $$C$$ coordinate system.\n\n\n$${}^Cp^i_j (i,j=1,2,3)$$ : Reflection of $${}^Xp^i$$ by $$\\pi_j$$ in the camera $$C$$ coordinate system.\n\n\n$$q^i_j (i,j=1,2,3)$$ : 2D projection of $${}^Cp^i_j$$ in the camera $$C$$ image screen.\n\n\n\n\nThe goal is to estimate the relative rotation $$R$$ and translation $$T$$ between the camera $$C$$ and the reference $$X$$ which satisfy\n\n\n\n\n$${}^Cp^i = R \\cdot {}^Xp^i + T (i=1,2,3) $$. (1)\n\n\n\n\nby knowing $$q^i_j (i,j=1,2,3)$$, the projections of $${}^Xp^i$$ observed via three different mirrors $$\\pi_j (j=1,2,3)$$ of unknown positions. The orientation and the position of t\nhe mirrors (the distances from the camera to the mirrors) are also estimated as a result.\nSo the input / output of the above-mentioned \ntnm.m\n can be expressed as follows.\n\n\n\n\ntnm.m\n\n\nInput $$q^i_j (i,j=1,2,3)$$ : 2D projections of three reference points observed via three mirrors $$\\pi_j (j=1,2,3)$$.\n\n\nOutput:\n\n\n$$R, T$$ : The relative posture and position between the camera $$C$$ and the reference $$X$$.\n\n\n$${}^Cn_j, d_j (j=1,2,3)$$ : The orientations and distances of the three mirrors $$\\pi_j (j=1,2,3)$$.\n\n\n\n\n\n\n\n\n\n\n\n\nSub-functions\n\n\nOur mirror-based calibration method consists of the following three steps, and we provide implementations corresponding to them.\n\n\n\n\n\n\nsub_p3p.m\n: P3P per mirrored image.\n\n\n\n\nInput:\n\n\n$${}^Xp^i (i=1,2,3)$$ : Three reference points, and\n\n\n$$q^i (i)$$ : their projections observed via a mirror $$\\pi$$.\n\n\n\n\n\n\nOutput: Up to 4 possible solutions of $${}^Cp^i$$\n\n\n\n\n\n\n\n\nsub_tnm_orth.m\n: Unique solution selection using an orthogonality constraint.\n\n\n\n\nInput: 64 sets of $${}^Cp^i_j (i,j=1,2,3)$$.\n\n\nOutput: The set of $${}^Cp^i_j (i,j=1,2,3)$$ which follows the orthogonality constraint best.\n\n\n\n\n\n\nsub_tnm_rt.m\n: Linear estimation of $$R$$ and $$T$$.\n\n\nInput: $${}^Cp^i_j (i,j=1,2,3)$$.\n\n\nOutput: $$R, T, n_j, d_j (j=1,2,3)$$.\n\n\n\n\n\n\n\n\nAnd in addition, we use the following sub-function for evaluation purpose.\n\n\n\n\nsub_reproj.m\n: Reprojection error evaluation\n\n\nInput:\n\n\n$${}^Xp^i (i=1,\\dots)$$ : Any number of reference points.\n\n\n$$q^i_j (i=1,\\dots, j=1,2,3)$$ : The projections of the reference points via mirrors.\n\n\n$$R, T, n_j, d_j (j=1,2,3)$$ : Estimated parameters.\n\n\n\n\n\n\nOutput: Average reprojection error.\n\n\n\n\n\n\n\n\nHow to use the OpenCV version with sample data\n\n\nUsage\n\n\nAfter unzipping the downloaded file, you will have the following files in a single directory named \n./tnm-opencv\n.\n\n\n\n\ndata/input{1,2,3}.png\n : Three input images. They are the original pictures WITH lens distortions.\n\n\ndata/input{1,2,3}.txt\n : Three input data points extracted from input{1,2,3}.png. The points are taken from undistorted images.\n\n\nMakefile\n : makefile.\n\n\ndemo.cc\n : A demo program to run our method.\n\n\nsub_solveP3P.h\n : A sub-function called from tnm.h to solve P3P problem.\n\n\ntnm.h\n : An implementation of our calibration method.\n\n\n\n\nThis code requires OpenCV 2.3. We used libcv-dev package in \nDebian wheezy\n. For Debian/Ubuntu, try\n\n\n $ sudo apt-get -f install libcv-dev libcvaux-dev libhighgui-dev g++ make\n\n\n\n\nto install requisite libraries and compilation tools, and then exec\n\n\n $ make\n\n\n\n\nto compile the code.\n\n\nFor Visual C++ on Windows, please simply import \ndemo.cc\n, \nsub_solveP3P.h\n, and \ntnm.h\n into a new project, and compile it (you need to setup additional include path and libraries for Op\nenCV, of course).\n\n\nOnce compiled, run the binary (named \ndemo\n) with no args in the \n./tnm-opencv\n directory.\n\n\n $ ./demo\n loading 'data/input1.txt' = [263.854279, 284.595978;\n   380.608337, 284.673645;\n   261.375946, 355.315582]\n\n loading 'data/input2.txt' = [187.462204, 264.845764;\n   302.664276, 261.313538;\n   183.416656, 338.876984]\n\n loading 'data/input3.txt' = [393.80719, 301.828278;\n   529.568542, 311.569794;\n   391.23999, 374.259766]\n\n loading 'data/model.txt' = [0, 0, 0;\n   175, 0, 0;\n   0, 100, 0]\n\n loading 'data/camera.txt' = [487.910797, 0, 324.31308;\n   0, 487.558441, 237.003937;\n   0, 0, 1]\n\n\n Average reprojection error by TNM : 0.353531 pixels\n\n ==== Parameters by TNM ====\n\n R  = [0.9552278293542109, -0.0315692738655991, -0.2941822138995512;\n   0.02622804982091903, 0.9994120031779081, -0.02208477544627536;\n   0.294706436016986, 0.01338016634873504, 0.9554941589139341]\n\n T  = [71.67155976406129; 84.34036742140127; 120.2696306131992]\n\n n1 = [0.2679446927390354; 0.03066392138399924; -0.9629461903753189]\n\n n2 = [0.4356434955333516; 0.08437398428883026; -0.8961561111629551]\n\n n3 = [-0.04427539436835728; -0.01119106464381498; -0.9989566805050478]\n\n d1 = 386.23\n\n d2 = 355.048\n\n d3 = 404.707\n\n\n\n\nThis program automatically loads data from \ndata/input{1,2,3}.txt\n, and then outputs the estimated parameters to stdout.\n\n\nBrief descriptions of the code\n\n\nThe structure of the code is very straightforward. Please visit the \nmain()\n function in \ndemo.cc\n first. The flow of \nmain()\n is:\n\n\n\n\nload data from files (\nmodel.txt\n, \ninput{1,2,3}.txt\n) by \nload()\n function defined in \ndemo.cc\n.\n\n\nrun calibration by \ntnm()\n function defined in tnm.h. What this function does inside is:\n\n\ncall \nsub_solveP3P()\n defined in \nsub_solveP3P.h\n for each input data (= the Matlab function in \ntnm-matlab/sub_p3p.m\n),\n\n\ncall \nsub_tnm_orth()\n defined in \ntnm.h\n (= the Matlab function in \ntnm-matlab/sub_tnm_orth.m\n), and\n\n\ncall \nsub_tnm_rt()\n defined in \ntnm.h\n (= the Matlab function in \ntnm-matlab/sub_tnm_rt.m\n).\n\n\nrun \nsub_reproj()\n defined in \ndemo.cc\n to evaluate the reprojection error (= the Matlab function in \ntnm-matlab/sub_reproj.m\n).\n\n\n\n\nSo to re-use the code for your own project, copy \ntnm.h\n and \nsub_solveP3P.h\n, and then use \ntnm()\n for calibration. To understand how to prepare the data, please consult the \nload()\n f\nunction in \ndemo.cc\n.\n\n\nHow to use the code with your own data\n\n\nTo calibrate your own system, please follow the process below. In short, update \ndata/model.txt\n and \ndata/input{1,2,3}.txt\n, then run the program again.\n\n\n\n\nSuppose you have a reference object $$X$$ and a camera $$C$$.\n\n\nThe intrinsic parameters of $$C$$ should be provided. You can use OpenCV to estimate them.\n\n\n\n\n\n\nCapture three images of $$X$$ as $$I_1, I_2, I_3$$ via mirrors $$\\pi_1, \\pi_2, \\pi_3$$ under different poses.\n\n\nDetect three points of $$X$$ for each of the images ($$I_1, I_2, I_3$$).\n\n\nHere we assume that the images are rectified (undistorted) using the intrinsic parameters before the detection.\n\n\nIf you used a chessboard pattern as $$X$$ and used OpenCV \nfindChessboardCorners()\n to detect it in $$I_1, I_2, I_3$$ automatically, you need to \nflip\n the detection result because the detector does not account for the observation via mirror.\n\n\n\n\n\n\n\n\nStore the data into \ndata/model.txt\n and \ndata/input{1,2,3}.txt\n.\n\n\n\n\ndata/model.txt\n is a line-oriented plain text file each of lines represents the 3D position of a reference point in $$X$$.\n0.000000 0.000000 0.000000\n175.000000 0.000000 0.000000\n0.000000 100.000000 0.000000\n\n\n\n\n\n\n\n\n\n\n\ndata/input{1,2,3}.txt\n are also line-oriented plain text files, and each of lines represents the 2D projection of the corresponding 3D reference point in \ndata/model.txt\n. For examp\nle, the first line below is the projection of the first reference point $$(0,0,0)$$ defined in the first line of \ndata/model.txt\n.\n\n\n380.608337 284.673645\n263.854279 284.595978\n377.368225 350.688141\n\n\n\n\n\n\n\nExec the demo program again, and you will get the result.\n\n\n\n\n\n\nContact\n\n\n\n\nShohei NOBUHARA",
            "title": "Ver.1"
        },
        {
            "location": "/v1/#introduction",
            "text": "This page explains how to use the 3-points version. For the general n-pts version, see  matlab/demo.m  in  GitHub .",
            "title": "Introduction"
        },
        {
            "location": "/v1/#how-to-use-the-matlab-version-with-sample-data",
            "text": "",
            "title": "How to use the Matlab version with sample data"
        },
        {
            "location": "/v1/#usage",
            "text": "After unzipping the downloaded file, you will have the following files in a single directory named  tnm .   data/input{1,2,3}.png  : Three input images. They are the original pictures WITH lens distortions.  data/input{1,2,3}.txt  : Three input data points extracted from  input{1,2,3}.png . The points are taken from undistorted images.  camera.txt  : The intrinsic parameter of the camera.  model.txt  : The reference object.  demo.m  : A demo program to run our method.  tnm.m  : An implementation of our calibration method.  sub_p3p.m  : A sub-function called from  tnm.m  to solve P3P problem.  sub_tnm_orth.m  : A sub-function called from  tnm.m .  sub_tnm_rt.m  : A sub-function called from  tnm.m .  sub_reproj.m  : To calc reprojection error.   Start Matlab, and change the working directory to the  tnm  directory. Run  demo.m  and you should see the following outputs and a pop-up window that visualizes the results.  > demo.m\nAverage reprojection error by TNM : 0.353531 pixel.\n\n==== Parameters by TNM ====\nR =\n    0.9552   -0.0316   -0.2942\n    0.0262    0.9994   -0.0221\n    0.2947    0.0134    0.9555\nT =\n   71.6716\n   84.3404\n  120.2696\nn1 =\n    0.2679\n    0.0307\n   -0.9629\nn2 =\n    0.4356\n    0.0844\n   -0.8962\nn3 =\n   -0.0443\n   -0.0112\n   -0.9990\nd1 =\n  386.2302\nd2 =\n  355.0478\nd3 =\n  404.7066",
            "title": "Usage"
        },
        {
            "location": "/v1/#brief-descriptions-of-the-code",
            "text": "",
            "title": "Brief descriptions of the code"
        },
        {
            "location": "/v1/#tnmm-top-level-driver",
            "text": "The figure below illustrates the measurement model of our method.   In this figure, we use the following notations. Notice that $${}^Yx$$ denotes $$x$$ in $$Y$$ coordinate system.   $$C$$ : camera.  $$\\pi_j (j=1,2,3)$$ : three mirrors.  $${}^Cn_j (j=1,2,3)$$ : the normal vector of $$\\pi_j$$.  $$d_j (j=1,2,3)$$ : the distance from $$C$$ to $$\\pi_j$$.  $${}^Xp^i (i=1,2,3)$$ : three reference points in the reference object coordinate system.  $${}^Cp^i (i=1,2,3)$$ : $${}^Xp^i$$ in the camera $$C$$ coordinate system.  $${}^Cp^i_j (i,j=1,2,3)$$ : Reflection of $${}^Xp^i$$ by $$\\pi_j$$ in the camera $$C$$ coordinate system.  $$q^i_j (i,j=1,2,3)$$ : 2D projection of $${}^Cp^i_j$$ in the camera $$C$$ image screen.   The goal is to estimate the relative rotation $$R$$ and translation $$T$$ between the camera $$C$$ and the reference $$X$$ which satisfy   $${}^Cp^i = R \\cdot {}^Xp^i + T (i=1,2,3) $$. (1)   by knowing $$q^i_j (i,j=1,2,3)$$, the projections of $${}^Xp^i$$ observed via three different mirrors $$\\pi_j (j=1,2,3)$$ of unknown positions. The orientation and the position of t\nhe mirrors (the distances from the camera to the mirrors) are also estimated as a result.\nSo the input / output of the above-mentioned  tnm.m  can be expressed as follows.   tnm.m  Input $$q^i_j (i,j=1,2,3)$$ : 2D projections of three reference points observed via three mirrors $$\\pi_j (j=1,2,3)$$.  Output:  $$R, T$$ : The relative posture and position between the camera $$C$$ and the reference $$X$$.  $${}^Cn_j, d_j (j=1,2,3)$$ : The orientations and distances of the three mirrors $$\\pi_j (j=1,2,3)$$.",
            "title": "tnm.m : top-level driver"
        },
        {
            "location": "/v1/#sub-functions",
            "text": "Our mirror-based calibration method consists of the following three steps, and we provide implementations corresponding to them.    sub_p3p.m : P3P per mirrored image.   Input:  $${}^Xp^i (i=1,2,3)$$ : Three reference points, and  $$q^i (i)$$ : their projections observed via a mirror $$\\pi$$.    Output: Up to 4 possible solutions of $${}^Cp^i$$     sub_tnm_orth.m : Unique solution selection using an orthogonality constraint.   Input: 64 sets of $${}^Cp^i_j (i,j=1,2,3)$$.  Output: The set of $${}^Cp^i_j (i,j=1,2,3)$$ which follows the orthogonality constraint best.    sub_tnm_rt.m : Linear estimation of $$R$$ and $$T$$.  Input: $${}^Cp^i_j (i,j=1,2,3)$$.  Output: $$R, T, n_j, d_j (j=1,2,3)$$.     And in addition, we use the following sub-function for evaluation purpose.   sub_reproj.m : Reprojection error evaluation  Input:  $${}^Xp^i (i=1,\\dots)$$ : Any number of reference points.  $$q^i_j (i=1,\\dots, j=1,2,3)$$ : The projections of the reference points via mirrors.  $$R, T, n_j, d_j (j=1,2,3)$$ : Estimated parameters.    Output: Average reprojection error.",
            "title": "Sub-functions"
        },
        {
            "location": "/v1/#how-to-use-the-opencv-version-with-sample-data",
            "text": "",
            "title": "How to use the OpenCV version with sample data"
        },
        {
            "location": "/v1/#usage_1",
            "text": "After unzipping the downloaded file, you will have the following files in a single directory named  ./tnm-opencv .   data/input{1,2,3}.png  : Three input images. They are the original pictures WITH lens distortions.  data/input{1,2,3}.txt  : Three input data points extracted from input{1,2,3}.png. The points are taken from undistorted images.  Makefile  : makefile.  demo.cc  : A demo program to run our method.  sub_solveP3P.h  : A sub-function called from tnm.h to solve P3P problem.  tnm.h  : An implementation of our calibration method.   This code requires OpenCV 2.3. We used libcv-dev package in  Debian wheezy . For Debian/Ubuntu, try   $ sudo apt-get -f install libcv-dev libcvaux-dev libhighgui-dev g++ make  to install requisite libraries and compilation tools, and then exec   $ make  to compile the code.  For Visual C++ on Windows, please simply import  demo.cc ,  sub_solveP3P.h , and  tnm.h  into a new project, and compile it (you need to setup additional include path and libraries for Op\nenCV, of course).  Once compiled, run the binary (named  demo ) with no args in the  ./tnm-opencv  directory.   $ ./demo\n loading 'data/input1.txt' = [263.854279, 284.595978;\n   380.608337, 284.673645;\n   261.375946, 355.315582]\n\n loading 'data/input2.txt' = [187.462204, 264.845764;\n   302.664276, 261.313538;\n   183.416656, 338.876984]\n\n loading 'data/input3.txt' = [393.80719, 301.828278;\n   529.568542, 311.569794;\n   391.23999, 374.259766]\n\n loading 'data/model.txt' = [0, 0, 0;\n   175, 0, 0;\n   0, 100, 0]\n\n loading 'data/camera.txt' = [487.910797, 0, 324.31308;\n   0, 487.558441, 237.003937;\n   0, 0, 1]\n\n\n Average reprojection error by TNM : 0.353531 pixels\n\n ==== Parameters by TNM ====\n\n R  = [0.9552278293542109, -0.0315692738655991, -0.2941822138995512;\n   0.02622804982091903, 0.9994120031779081, -0.02208477544627536;\n   0.294706436016986, 0.01338016634873504, 0.9554941589139341]\n\n T  = [71.67155976406129; 84.34036742140127; 120.2696306131992]\n\n n1 = [0.2679446927390354; 0.03066392138399924; -0.9629461903753189]\n\n n2 = [0.4356434955333516; 0.08437398428883026; -0.8961561111629551]\n\n n3 = [-0.04427539436835728; -0.01119106464381498; -0.9989566805050478]\n\n d1 = 386.23\n\n d2 = 355.048\n\n d3 = 404.707  This program automatically loads data from  data/input{1,2,3}.txt , and then outputs the estimated parameters to stdout.",
            "title": "Usage"
        },
        {
            "location": "/v1/#brief-descriptions-of-the-code_1",
            "text": "The structure of the code is very straightforward. Please visit the  main()  function in  demo.cc  first. The flow of  main()  is:   load data from files ( model.txt ,  input{1,2,3}.txt ) by  load()  function defined in  demo.cc .  run calibration by  tnm()  function defined in tnm.h. What this function does inside is:  call  sub_solveP3P()  defined in  sub_solveP3P.h  for each input data (= the Matlab function in  tnm-matlab/sub_p3p.m ),  call  sub_tnm_orth()  defined in  tnm.h  (= the Matlab function in  tnm-matlab/sub_tnm_orth.m ), and  call  sub_tnm_rt()  defined in  tnm.h  (= the Matlab function in  tnm-matlab/sub_tnm_rt.m ).  run  sub_reproj()  defined in  demo.cc  to evaluate the reprojection error (= the Matlab function in  tnm-matlab/sub_reproj.m ).   So to re-use the code for your own project, copy  tnm.h  and  sub_solveP3P.h , and then use  tnm()  for calibration. To understand how to prepare the data, please consult the  load()  f\nunction in  demo.cc .",
            "title": "Brief descriptions of the code"
        },
        {
            "location": "/v1/#how-to-use-the-code-with-your-own-data",
            "text": "To calibrate your own system, please follow the process below. In short, update  data/model.txt  and  data/input{1,2,3}.txt , then run the program again.   Suppose you have a reference object $$X$$ and a camera $$C$$.  The intrinsic parameters of $$C$$ should be provided. You can use OpenCV to estimate them.    Capture three images of $$X$$ as $$I_1, I_2, I_3$$ via mirrors $$\\pi_1, \\pi_2, \\pi_3$$ under different poses.  Detect three points of $$X$$ for each of the images ($$I_1, I_2, I_3$$).  Here we assume that the images are rectified (undistorted) using the intrinsic parameters before the detection.  If you used a chessboard pattern as $$X$$ and used OpenCV  findChessboardCorners()  to detect it in $$I_1, I_2, I_3$$ automatically, you need to  flip  the detection result because the detector does not account for the observation via mirror.     Store the data into  data/model.txt  and  data/input{1,2,3}.txt .   data/model.txt  is a line-oriented plain text file each of lines represents the 3D position of a reference point in $$X$$. 0.000000 0.000000 0.000000\n175.000000 0.000000 0.000000\n0.000000 100.000000 0.000000      data/input{1,2,3}.txt  are also line-oriented plain text files, and each of lines represents the 2D projection of the corresponding 3D reference point in  data/model.txt . For examp\nle, the first line below is the projection of the first reference point $$(0,0,0)$$ defined in the first line of  data/model.txt .  380.608337 284.673645\n263.854279 284.595978\n377.368225 350.688141    Exec the demo program again, and you will get the result.",
            "title": "How to use the code with your own data"
        },
        {
            "location": "/v1/#contact",
            "text": "Shohei NOBUHARA",
            "title": "Contact"
        },
        {
            "location": "/v2/",
            "text": "Introduction\n\n\nThis page explains how to use the n-points / m-mirrors version.\n\n\nPrerequisite\n\n\nThe current implementation depends on \nEPnP provided by EPFL\n. Please download the matlab code and extract them in \n./matlab/\n directory. Our code calls \n./matlab/efficient_pnp_gauss.m\n internally.\n\n\nUsage\n\n\nThe usage is essentially identical to the \n3-points / 3-mirrors version\n. See \nmatlab/demo.m\n to change the number of points and mirrors.\n\n\nLimitations\n\n\nC++ version is not available for now.",
            "title": "Ver.2"
        },
        {
            "location": "/v2/#introduction",
            "text": "This page explains how to use the n-points / m-mirrors version.",
            "title": "Introduction"
        },
        {
            "location": "/v2/#prerequisite",
            "text": "The current implementation depends on  EPnP provided by EPFL . Please download the matlab code and extract them in  ./matlab/  directory. Our code calls  ./matlab/efficient_pnp_gauss.m  internally.",
            "title": "Prerequisite"
        },
        {
            "location": "/v2/#usage",
            "text": "The usage is essentially identical to the  3-points / 3-mirrors version . See  matlab/demo.m  to change the number of points and mirrors.",
            "title": "Usage"
        },
        {
            "location": "/v2/#limitations",
            "text": "C++ version is not available for now.",
            "title": "Limitations"
        }
    ]
}