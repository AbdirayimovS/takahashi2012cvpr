{
  "name": "Mirror-based Camera Pose Estimation Using an Orthogonality Constraint",
  "tagline": "",
  "body": "### Introduction\r\nThis page provides an implementation of our mirror-based camera calibration algorithm presented as\r\n```\r\nK. Takahashi, S. Nobuhara and T. Matsuyama: A New Mirror-based Extrinsic Camera Calibration Using an Orthogonality Constraint, CVPR2012\r\n```\r\nand\r\n```\r\nK. Takahashi, S. Nobuhara and T. Matsuyama: Mirror-based Camera Pose Estimation Using an Orthogonality Constraint, IPSJ Transactions on Computer Vision and Applications, Vol.8, pp.11--19, 2016\r\n```\r\n* paper: [CVPR](takahashi12new.pdf) [Journal](http://doi.org/10.2197/ipsjtcva.8.11)\r\n* movie: [mp4](takahashi12new.mp4)\r\n* bibtex:\r\n```\r\n@inproceedings{takahashi12new,\r\n  title = {A New Mirror-based Extrinsic Camera Calibration Using an Orthogonality Constraint},\r\n  author = {Kosuke Takahashi and Shohei Nobuhara and Takashi Matsuyama},\r\n  booktitle = {Proc.\\ of CVPR},\r\n  year = {2012},\r\n}\r\n```\r\nThe motivation of this project is to calibrate a camera w.r.t. a reference object which is not observable from the camera. This happens, for example, in display-camera systems such as digital signage, webcam attached to laptop PC, etc. Once obtained the mapping between the display pixel coordinate system and the camera coordinate system, it becomes possible to compute the gazing point (pixel) of a person in front of the display by estimating the gazing direction in the camera coordinate system. This scenario allows the person to move freely, while conventional methods typically restrict the head position to be fixed.\r\n\r\nThe key point to solve the problem is the use of mirrored images. Suppose we have a single static camera CC and a static reference object $$X$$ as shown below. The camera CC cannot observe the reference object XX directly. Instead, we use a mirror ππ and let the camera CC observe the reference object XX through it. The goal of our mirror-based calibration is to estimate the relative posture RR and position TT of the camera CC against the reference object XX by observing three points of XX via three mirrors πj(j=1,2,3)πj(j=1,2,3) under different unknown positions and orientations.\r\n\r\n# Source code\r\n\r\n## License\r\nThis source code is provided under the [BSD 3-Clause license](http://www.opensource.org/licenses/BSD-3-Clause).\r\n```\r\nCopyright (c) 2012, Kosuke Takahashi, Shohei Nobuhara and Takashi Matsuyama\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n   * Redistributions of source code must retain the above copyright notice,\r\n     this list of conditions and the following disclaimer.\r\n   * Redistributions in binary form must reproduce the above copyright\r\n     notice, this list of conditions and the following disclaimer in the\r\n     documentation and/or other materials provided with the distribution.\r\n   * Neither the name of the Graduate School of Informatics, Kyoto\r\n     University, Japan nor the names of its contributors may be used to\r\n     endorse or promote products derived from this software without specific\r\n     prior written permission.\r\n\r\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\r\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\r\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\r\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\r\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\r\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\r\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\r\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\r\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\r\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\r\nPOSSIBILITY OF SUCH DAMAGE.\r\n```\r\n\r\n## Download links\r\nIf you use this software, please consider citing the aforementioned paper in any resulting publication.\r\n* Matlab version with test data: tnm-matlab.zip (tested with Matlab 2011b and 2012a. Also compatible with GNU Octave v3.6 + Octave-Forge)\r\n* OpenCV version with test data: tnm-opencv.zip (tested with Debian wheezy + libcv-dev package)\r\n\r\n\r\n# How to use the Matlab version with sample data \r\n\r\n## Usage\r\n\r\nAfter unzipping the downloaded file, you will have the following files in a single directory named \"tnm\".\r\n* `data/input{1,2,3}.png` : Three input images. They are the original pictures WITH lens distortions.\r\n* `data/input{1,2,3}.txt` : Three input data points extracted from `input{1,2,3}.png`. The points are taken from undistorted images.\r\n* `camera.txt` : The intrinsic parameter of the camera.\r\n* `model.txt` : The reference object.\r\n* `demo.m` : A demo program to run our method.\r\n* `tnm.m` : An implementation of our calibration method.\r\n* `sub_p3p.m` : A sub-function called from `tnm.m` to solve P3P problem.\r\n* `sub_tnm_orth.m` : A sub-function called from `tnm.m`.\r\n* `sub_tnm_rt.m` : A sub-function called from `tnm.m`.\r\n* `sub_reproj.m` : To calc reprojection error.\r\n\r\nStart Matlab, and change the working directory to the \"tnm\" directory. Run `demo.m` and you should see the following outputs and a pop-up window that visualizes the results.\r\n```\r\n> demo.m\r\nAverage reprojection error by TNM : 0.353531 pixel.\r\n\r\n==== Parameters by TNM ====\r\nR =\r\n    0.9552   -0.0316   -0.2942\r\n    0.0262    0.9994   -0.0221\r\n    0.2947    0.0134    0.9555\r\nT =\r\n   71.6716\r\n   84.3404\r\n  120.2696\r\nn1 =\r\n    0.2679\r\n    0.0307\r\n   -0.9629\r\nn2 =\r\n    0.4356\r\n    0.0844\r\n   -0.8962\r\nn3 =\r\n   -0.0443\r\n   -0.0112\r\n   -0.9990\r\nd1 =\r\n  386.2302\r\nd2 =\r\n  355.0478\r\nd3 =\r\n  404.7066\r\n```\r\n\r\n## Brief descriptions of the code\r\n\r\n### `tnm.m` : top-level driver\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}